{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from importlib import reload  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from loglizer.models import InvariantsMiner, PCA, IsolationForest, OneClassSVM, LogClustering, LR, SVM\n",
    "from loglizer import dataloader, preprocessing\n",
    "from loglizer.utils import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouput_dir = \"../output/no_shuffle_bgl_325/\"\n",
    "# middle_dir = \"\"\n",
    "# log_file = \"BGL.log\"\n",
    "\n",
    "ouput_dir = r\"E:\\logbert-main\\datasets\\jeecgboot/\"\n",
    "middle_dir = \"\"\n",
    "log_file = \"jeecgboot.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Produce event templates from train test dataset -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train normal size: 2354\n",
      "Train abnormal size: 558\n",
      "Test normal size: 3886\n",
      "Test abnormal size: 837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\logbert-main\\loglizer\\dataloader.py:286: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train = np.array(train).reshape(-1, 1)\n",
      "E:\\logbert-main\\loglizer\\dataloader.py:292: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_normal = np.array(test_normal).reshape(-1,1)\n",
      "E:\\logbert-main\\loglizer\\dataloader.py:298: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  abnormal = np.array(abnormal).reshape(-1,1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = dataloader.load_data(ouput_dir, middle_dir, log_file, is_mapping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Transformed train data summary ======\n",
      "Train data shape: 2912-by-98\n",
      "\n",
      "====== Transformed test data summary ======\n",
      "Test data shape: 4723-by-98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = preprocessing.FeatureExtractor()\n",
    "x_train = feature_extractor.fit_transform(x_train)\n",
    "x_test = feature_extractor.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Model: PCA ====================\n",
      "theshold 0\n",
      "====== Model summary ======\n",
      "n_components: 2\n",
      "Project matrix shape: 98-by-98\n",
      "SPE threshold: 1\n",
      "\n",
      "Train validation:\n",
      "====== Evaluation summary ======\n",
      "Confusion Matrix: TP: 558, FP: 1644, TN: 710, FN: 0\n",
      "Precision: 25.341%, recall: 100.000%, F1-measure: 40.435%\n",
      "\n",
      "Test validation:\n",
      "====== Evaluation summary ======\n",
      "Confusion Matrix: TP: 837, FP: 3573, TN: 313, FN: 0\n",
      "Precision: 18.980%, recall: 100.000%, F1-measure: 31.904%\n",
      "\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"=\"*20 + \" Model: PCA \" + \"=\"*20)\n",
    "for th in np.arange(1):\n",
    "    print(\"theshold\", th)\n",
    "    model = PCA(n_components=0.8, threshold=1, c_alpha = 1.9600)\n",
    "    model.fit(x_train)\n",
    "    print('Train validation:')\n",
    "    precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "    print('Test validation:')\n",
    "    precision, recall, f1 = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Model: IsolationForest ====================\n",
      "====== Model summary ======\n",
      "Train validation:\n",
      "====== Evaluation summary ======\n",
      "Confusion Matrix: TP: 55, FP: 13, TN: 2341, FN: 503\n",
      "Precision: 80.882, recall: 9.857, F1-measure: 17.572\n",
      "\n",
      "Test validation:\n",
      "====== Evaluation summary ======\n",
      "Confusion Matrix: TP: 71, FP: 12, TN: 3874, FN: 766\n",
      "Precision: 85.542, recall: 8.483, F1-measure: 15.435\n",
      "\n",
      "CPU times: total: 391 ms\n",
      "Wall time: 462 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"=\"*20 + \" Model: IsolationForest \" + \"=\"*20)\n",
    "model = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto', random_state=19)\n",
    "model.fit(x_train)\n",
    "print('Train validation:')\n",
    "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "print('Test validation:')\n",
    "precision, recall, f1 = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Model: one class SVM ====================\n",
      "====== Model summary ======\n",
      "Train validation:\n",
      "====== Evaluation summary ======\n",
      "Confusion Matrix: TP: 185, FP: 2354, TN: 0, FN: 373\n",
      "Precision: 7.286, recall: 33.154, F1-measure: 11.947\n",
      "\n",
      "Test validation:\n",
      "====== Evaluation summary ======\n",
      "Confusion Matrix: TP: 276, FP: 3886, TN: 0, FN: 561\n",
      "Precision: 6.631, recall: 32.975, F1-measure: 11.042\n",
      "\n",
      "CPU times: total: 1.25 s\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"=\"*20 + \" Model: one class SVM \" + \"=\"*20)\n",
    "model = OneClassSVM(kernel='rbf')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('Train validation:')\n",
    "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "print('Test validation:')\n",
    "precision, recall, f1 = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Model: LogClustering ====================\n",
      "====== Model summary ======\n",
      "Starting offline clustering...\n",
      "Processed 1000 instances.\n",
      "Found 46 clusters offline.\n",
      "\n",
      "Starting online clustering...\n",
      "Processed 2000 instances.\n",
      "Processed 2354 instances.\n",
      "Found 79 clusters online.\n",
      "\n",
      "Train validation:\n",
      "====== Evaluation summary ======\n",
      "Confusion Matrix: TP: 556, FP: 2286, TN: 68, FN: 2\n",
      "Precision: 19.564, recall: 99.642, F1-measure: 32.706\n",
      "\n",
      "Test validation:\n",
      "====== Evaluation summary ======\n",
      "Confusion Matrix: TP: 835, FP: 3867, TN: 19, FN: 2\n",
      "Precision: 17.758, recall: 99.761, F1-measure: 30.150\n",
      "\n",
      "CPU times: total: 8.67 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"=\"*20 + \" Model: LogClustering \" + \"=\"*20)\n",
    "max_dist = 0.3  # the threshold to stop the clustering process\n",
    "anomaly_threshold = 0  # the threshold for anomaly detection\n",
    "model = LogClustering(max_dist=max_dist, anomaly_threshold=anomaly_threshold)\n",
    "model.fit(x_train[y_train == 0, :])  # Use only normal samples for training\n",
    "print('Train validation:')\n",
    "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "print('Test validation:')\n",
    "precision, recall, f1 = model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\LogBert\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\LogBert\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\envs\\LogBert\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                              Unnamed: 0  Label\n0                                                     0   False\n1                                                     1   False\n2                                                     2   False\n3                                                     3   False\n4                                                     4   False\n...                                                  ...    ...\n10557      52 58 53 54 55 53 65 55 53 56 55 52 53 57 55    True\n10558         53 56 55 53 56 55 53 56 55 52 58 53 54 55    True\n10559            53 56 55 52 53 54 55 60 61 55 53 56 55   False\n10560  53 56 55 53 56 55 53 56 55 52 53 57 55 53 56 5...   True\n10561                           53 56 55 53 56 55 53 56     NaN\n\n[10562 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10557</th>\n      <td>52 58 53 54 55 53 65 55 53 56 55 52 53 57 55</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10558</th>\n      <td>53 56 55 53 56 55 53 56 55 52 58 53 54 55</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10559</th>\n      <td>53 56 55 52 53 54 55 60 61 55 53 56 55</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10560</th>\n      <td>53 56 55 53 56 55 53 56 55 52 53 57 55 53 56 5...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10561</th>\n      <td>53 56 55 53 56 55 53 56</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>10562 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取文件seq.csv\n",
    "import pandas as pd\n",
    "\n",
    "seq = pd.read_csv(r\"E:\\logbert-main\\datasets\\jeecgboot\\seq.csv\")\n",
    "# None改名为Label\n",
    "seq.rename(columns={'None':'Label'}, inplace=True)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     Seq  Label\n0                                                     0     0.0\n1                                                     1     0.0\n2                                                     2     0.0\n3                                                     3     0.0\n4                                                     4     0.0\n...                                                  ...    ...\n10557      52 58 53 54 55 53 65 55 53 56 55 52 53 57 55     1.0\n10558         53 56 55 53 56 55 53 56 55 52 58 53 54 55     1.0\n10559            53 56 55 52 53 54 55 60 61 55 53 56 55     0.0\n10560  53 56 55 53 56 55 53 56 55 52 53 57 55 53 56 5...    1.0\n10561                           53 56 55 53 56 55 53 56     NaN\n\n[10562 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Seq</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10557</th>\n      <td>52 58 53 54 55 53 65 55 53 56 55 52 53 57 55</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10558</th>\n      <td>53 56 55 53 56 55 53 56 55 52 58 53 54 55</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10559</th>\n      <td>53 56 55 52 53 54 55 60 61 55 53 56 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10560</th>\n      <td>53 56 55 53 56 55 53 56 55 52 53 57 55 53 56 5...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10561</th>\n      <td>53 56 55 53 56 55 53 56</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>10562 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将Label列中的False改为0，True改为1\n",
    "seq['Label'] = seq['Label'].map({False:0, True:1})\n",
    "seq.rename(columns={'Unnamed: 0':'Seq'}, inplace=True)\n",
    "seq"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "deeplog_df_len = len(seq)\n",
    "data_len = deeplog_df_len\n",
    "train_len = int(data_len * 0.3)  # 训练集长度\n",
    "valid_len = int(data_len * 0.2)  # 验证集长度\n",
    "test_len = data_len - train_len - valid_len  # 测试集长度\n",
    "\n",
    "train_deeplog_df = seq.iloc[:train_len]  # 训练集\n",
    "valid_deeplog_df = seq.iloc[train_len:train_len + valid_len]  # 验证集\n",
    "test_deeplog_df = seq.iloc[train_len + valid_len:]  # 测试集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_len: 3168\n",
      "valid_len: 2112\n",
      "test_len: 5282\n"
     ]
    }
   ],
   "source": [
    "# len(train_deeplog_df)\n",
    "# len(valid_deeplog_df)\n",
    "# len(test_deeplog_df)\n",
    "print(\"train_len:\", len(train_deeplog_df))\n",
    "print(\"valid_len:\", len(valid_deeplog_df))\n",
    "print(\"test_len:\", len(test_deeplog_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_normal_df_len: 2354\n",
      "train_abnormal_df_len: 814\n"
     ]
    }
   ],
   "source": [
    "train_deeplog_df_len = int(len(train_deeplog_df))\n",
    "train_normal_df = train_deeplog_df[train_deeplog_df[\"Label\"] == 0]\n",
    "train_abnormal_df = train_deeplog_df[train_deeplog_df[\"Label\"] == 1]\n",
    "print(\"train_normal_df_len:\", len(train_normal_df))\n",
    "print(\"train_abnormal_df_len:\", len(train_abnormal_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_normal_df_len: 1411\n",
      "valid_abnormal_df_len: 701\n"
     ]
    }
   ],
   "source": [
    "valid_deeplog_df_len = int(len(valid_deeplog_df))\n",
    "valid_normal_df = valid_deeplog_df[valid_deeplog_df[\"Label\"] == 0]\n",
    "valid_abnormal_df = valid_deeplog_df[valid_deeplog_df[\"Label\"] == 1]\n",
    "print(\"valid_normal_df_len:\", len(valid_normal_df))\n",
    "print(\"valid_abnormal_df_len:\", len(valid_abnormal_df))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_normal_df_len: 3886\n",
      "test_abnormal_df_len: 1395\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           Seq  Label\n5282            53 56 55 53 56 55 52 53 54 55     0.0\n5284                                 53 65 55     0.0\n5285                        60 61 55 60 61 55     0.0\n5287                        60 88 55 53 56 55     0.0\n5288      60 61 55 53 56 55 53 56 55 60 61 55     0.0\n...                                        ...    ...\n10552                             52 53 57 55     0.0\n10553              53 56 55 53 56 55 53 56 55     0.0\n10555     60 64 55 53 56 55 53 56 55 53 65 55     0.0\n10556  53 65 55 52 53 57 55 53 56 55 53 56 55     0.0\n10559  53 56 55 52 53 54 55 60 61 55 53 56 55     0.0\n\n[3886 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Seq</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5282</th>\n      <td>53 56 55 53 56 55 52 53 54 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5284</th>\n      <td>53 65 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5285</th>\n      <td>60 61 55 60 61 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5287</th>\n      <td>60 88 55 53 56 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5288</th>\n      <td>60 61 55 53 56 55 53 56 55 60 61 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10552</th>\n      <td>52 53 57 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10553</th>\n      <td>53 56 55 53 56 55 53 56 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10555</th>\n      <td>60 64 55 53 56 55 53 56 55 53 65 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10556</th>\n      <td>53 65 55 52 53 57 55 53 56 55 53 56 55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10559</th>\n      <td>53 56 55 52 53 54 55 60 61 55 53 56 55</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3886 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_deeplog_df_len = int(len(test_deeplog_df))\n",
    "test_normal_df = test_deeplog_df[test_deeplog_df[\"Label\"] == 0]\n",
    "test_abnormal_df = test_deeplog_df[test_deeplog_df[\"Label\"] == 1]\n",
    "print(\"test_normal_df_len:\", len(test_normal_df))\n",
    "print(\"test_abnormal_df_len:\", len(test_abnormal_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# 将seq列下的所有值单独保存为numpy数组\n",
    "seq_np = seq['Seq'].values\n",
    "train_normal_df_np = train_normal_df['Seq'].values\n",
    "valid_normal_df_np = valid_normal_df['Seq'].values\n",
    "test_normal_df_np = test_normal_df['Seq'].values\n",
    "test_abnormal_df_np = test_abnormal_df['Seq'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "'60 61 55 60 64 55 '"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_np[500]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "seq_np_ls = []\n",
    "\n",
    "for i in range(len(seq_np)):\n",
    "    seq_np_ls.append(seq_np[i])\n",
    "\n",
    "train_normal_df_np_ls = []\n",
    "for i in range(len(train_normal_df_np)):\n",
    "    train_normal_df_np_ls.append(train_normal_df_np[i])\n",
    "\n",
    "valid_normal_df_np_ls = []\n",
    "for i in range(len(valid_normal_df_np)):\n",
    "    valid_normal_df_np_ls.append(valid_normal_df_np[i])\n",
    "\n",
    "test_normal_df_np_ls = []\n",
    "for i in range(len(test_normal_df_np)):\n",
    "    test_normal_df_np_ls.append(test_normal_df_np[i])\n",
    "\n",
    "test_abnormal_df_np_ls = []\n",
    "for i in range(len(test_abnormal_df_np)):\n",
    "    test_abnormal_df_np_ls.append(test_abnormal_df_np[i])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "for i in range(len(seq_np_ls)):\n",
    "    seq_np_ls[i] = seq_np_ls[i].split(' ')\n",
    "\n",
    "for i in range(len(train_normal_df_np_ls)):\n",
    "    train_normal_df_np_ls[i] = train_normal_df_np_ls[i].split(' ')\n",
    "\n",
    "for i in range(len(valid_normal_df_np_ls)):\n",
    "    valid_normal_df_np_ls[i] = valid_normal_df_np_ls[i].split(' ')\n",
    "\n",
    "for i in range(len(test_normal_df_np_ls)):\n",
    "    test_normal_df_np_ls[i] = test_normal_df_np_ls[i].split(' ')\n",
    "\n",
    "for i in range(len(test_abnormal_df_np_ls)):\n",
    "    test_abnormal_df_np_ls[i] = test_abnormal_df_np_ls[i].split(' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "for i in range(len(seq_np_ls)):\n",
    "    for j in range(len(seq_np_ls[i])):\n",
    "        if seq_np_ls[i][j] == '':\n",
    "            seq_np_ls[i].remove(seq_np_ls[i][j])\n",
    "        else:\n",
    "            seq_np_ls[i][j] = int(seq_np_ls[i][j])\n",
    "\n",
    "for i in range(len(train_normal_df_np_ls)):\n",
    "    for j in range(len(train_normal_df_np_ls[i])):\n",
    "        if train_normal_df_np_ls[i][j] == '':\n",
    "            train_normal_df_np_ls[i].remove(train_normal_df_np_ls[i][j])\n",
    "        else:\n",
    "            train_normal_df_np_ls[i][j] = int(train_normal_df_np_ls[i][j])\n",
    "\n",
    "for i in range(len(valid_normal_df_np_ls)):\n",
    "    for j in range(len(valid_normal_df_np_ls[i])):\n",
    "        if valid_normal_df_np_ls[i][j] == '':\n",
    "            valid_normal_df_np_ls[i].remove(valid_normal_df_np_ls[i][j])\n",
    "        else:\n",
    "            valid_normal_df_np_ls[i][j] = int(valid_normal_df_np_ls[i][j])\n",
    "\n",
    "for i in range(len(test_normal_df_np_ls)):\n",
    "    for j in range(len(test_normal_df_np_ls[i])):\n",
    "        if test_normal_df_np_ls[i][j] == '':\n",
    "            test_normal_df_np_ls[i].remove(test_normal_df_np_ls[i][j])\n",
    "        else:\n",
    "            test_normal_df_np_ls[i][j] = int(test_normal_df_np_ls[i][j])\n",
    "\n",
    "for i in range(len(test_abnormal_df_np_ls)):\n",
    "    for j in range(len(test_abnormal_df_np_ls[i])):\n",
    "        if test_abnormal_df_np_ls[i][j] == '':\n",
    "            test_abnormal_df_np_ls[i].remove(test_abnormal_df_np_ls[i][j])\n",
    "        else:\n",
    "            test_abnormal_df_np_ls[i][j] = int(test_abnormal_df_np_ls[i][j])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mls\u001B[49m\n",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mls\u001B[49m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\PyCharmPro\\PyCharm 2022.2.4\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PyCharmPro\\PyCharm 2022.2.4\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10562 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dc1140990a949c4b42ada12e3d60366"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open(r'E:\\logbert-main\\datasets\\jeecgboot/all_seq', 'w') as f:\n",
    "    for i in tqdm(range(len(seq_np_ls))):\n",
    "        for j in range(len(seq_np_ls[i])):\n",
    "            f.write(str(seq_np_ls[i][j]) + ' ')\n",
    "        f.write('\\n')\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2354 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2029a93be40346d7903edbc90df6584d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1411 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc3018e308ed46459db7811949b7e661"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3886 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac2b7f8d83534c888f13b3a8cc6e25e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1395 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e81277d1f2749d69673adea0de135f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open(r'E:\\logbert-main\\datasets\\jeecgboot/train', 'w') as f:\n",
    "    for i in tqdm(range(len(train_normal_df_np_ls))):\n",
    "        for j in range(len(train_normal_df_np_ls[i])):\n",
    "            f.write(str(train_normal_df_np_ls[i][j]) + ' ')\n",
    "        f.write('\\n')\n",
    "print('ok')\n",
    "\n",
    "with open(r'E:\\logbert-main\\datasets\\jeecgboot/valid', 'w') as f:\n",
    "    for i in tqdm(range(len(valid_normal_df_np_ls))):\n",
    "        for j in range(len(valid_normal_df_np_ls[i])):\n",
    "            f.write(str(valid_normal_df_np_ls[i][j]) + ' ')\n",
    "        f.write('\\n')\n",
    "print('ok')\n",
    "\n",
    "with open(r'E:\\logbert-main\\datasets\\jeecgboot/test_normal', 'w') as f:\n",
    "    for i in tqdm(range(len(test_normal_df_np_ls))):\n",
    "        for j in range(len(test_normal_df_np_ls[i])):\n",
    "            f.write(str(test_normal_df_np_ls[i][j]) + ' ')\n",
    "        f.write('\\n')\n",
    "print('ok')\n",
    "\n",
    "with open(r'E:\\logbert-main\\datasets\\jeecgboot/test_abnormal', 'w') as f:\n",
    "    for i in tqdm(range(len(test_abnormal_df_np_ls))):\n",
    "        for j in range(len(test_abnormal_df_np_ls[i])):\n",
    "            f.write(str(test_abnormal_df_np_ls[i][j]) + ' ')\n",
    "        f.write('\\n')\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
